{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AI-Driven Company Intelligence Analysis\n",
        "\n",
        "This notebook provides an interactive environment for analyzing company data and generating insights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from company_intelligence import CompanyIntelligence\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables (for API key)\n",
        "load_dotenv()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Initialize the analyzer\n",
        "# Replace with your data file path if different\n",
        "data_path = 'champions_group_data.xlsx'\n",
        "api_key = os.getenv('OPENAI_API_KEY')  # Optional: for LLM insights\n",
        "\n",
        "analyzer = CompanyIntelligence(data_path, api_key=api_key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Explore the Data\n",
        "\n",
        "**Note:** Inactive companies are automatically filtered out during data loading. Only companies with \"Active\" status are included in the analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Explore the raw data\n",
        "df_explored = analyzer.explore_data()\n",
        "\n",
        "# Display first few rows\n",
        "analyzer.df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check data types and missing values\n",
        "print(\"Data Info:\")\n",
        "analyzer.df.info()\n",
        "\n",
        "print(\"\\nMissing Values:\")\n",
        "missing = analyzer.df.isnull().sum()\n",
        "print(missing[missing > 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Preprocess Data\n",
        "\n",
        "**Note:** All numeric data will be automatically transformed using log base 10 (log10) before analysis. This helps normalize the data distribution and handle outliers. The transformation uses log10(1 + abs(x)) to handle zeros and negative values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Preprocess data\n",
        "# Exclude any columns you don't want in the analysis (e.g., IDs, notes)\n",
        "exclude_cols = []  # Add column names here if needed, e.g., ['Company_ID', 'Notes']\n",
        "\n",
        "analyzer.preprocess_data(exclude_cols=exclude_cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Determine Optimal Clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Find optimal number of clusters\n",
        "optimal_k = analyzer.determine_optimal_clusters(max_k=10)\n",
        "print(f\"\\nRecommended number of clusters: {optimal_k}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Perform Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Perform clustering\n",
        "# Option 1: Use optimal number (recommended)\n",
        "analyzer.perform_clustering()\n",
        "\n",
        "# Option 2: Specify custom number\n",
        "# analyzer.perform_clustering(n_clusters=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# View cluster distribution\n",
        "cluster_dist = analyzer.df['Cluster'].value_counts().sort_index()\n",
        "print(\"Cluster Distribution:\")\n",
        "print(cluster_dist)\n",
        "\n",
        "# Visualize\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 6))\n",
        "cluster_dist.plot(kind='bar')\n",
        "plt.title('Company Distribution Across Segments')\n",
        "plt.xlabel('Cluster')\n",
        "plt.ylabel('Number of Companies')\n",
        "plt.xticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Analyze Clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Analyze cluster characteristics\n",
        "cluster_analysis = analyzer.analyze_clusters()\n",
        "\n",
        "# Display summary for each cluster\n",
        "for cluster_id, info in cluster_analysis.items():\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Cluster {cluster_id}: {info['size']} companies ({info['percentage']:.1f}%)\")\n",
        "    print(f\"{'='*60}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Compare Clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Compare clusters across key features\n",
        "comparison = analyzer.compare_clusters()\n",
        "comparison"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Compare specific feature (replace 'Revenue' with actual column name)\n",
        "numeric_cols = analyzer.df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "if numeric_cols:\n",
        "    feature = numeric_cols[0]  # Use first numeric column\n",
        "    print(f\"Comparing '{feature}' across clusters:\")\n",
        "    feature_comparison = analyzer.compare_clusters(feature=feature)\n",
        "    print(feature_comparison)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Identify Patterns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Identify patterns, outliers, and anomalies\n",
        "patterns = analyzer.identify_patterns()\n",
        "\n",
        "print(\"Outliers Detected:\")\n",
        "for outlier in patterns['outliers'][:10]:\n",
        "    print(f\"  {outlier['feature']}: {outlier['count']} companies ({outlier['percentage']:.1f}%)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Generate Insights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Generate LLM-powered insights (or rule-based if LLM unavailable)\n",
        "insights = analyzer.generate_llm_insights(cluster_analysis, patterns)\n",
        "print(insights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Create Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Generate all visualizations\n",
        "analyzer.visualize_results()\n",
        "print(\"Visualizations saved!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create custom visualizations\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example: Feature distribution by cluster\n",
        "numeric_cols = analyzer.df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "numeric_cols = [col for col in numeric_cols if col != 'Cluster']\n",
        "\n",
        "if numeric_cols:\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for idx, feature in enumerate(numeric_cols[:4]):\n",
        "        analyzer.df.boxplot(column=feature, by='Cluster', ax=axes[idx])\n",
        "        axes[idx].set_title(f'{feature} by Cluster')\n",
        "        axes[idx].set_xlabel('Cluster')\n",
        "    \n",
        "    plt.suptitle('Feature Comparison Across Clusters', y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Generate Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Generate comprehensive report\n",
        "report = analyzer.generate_report(cluster_analysis, patterns, insights)\n",
        "print(\"Report generated and saved to company_intelligence_report.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11: Export Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Export data with cluster labels\n",
        "output_file = 'companies_with_segments.csv'\n",
        "analyzer.df.to_csv(output_file, index=False)\n",
        "print(f\"Results exported to {output_file}\")\n",
        "\n",
        "# Display sample of results\n",
        "analyzer.df[['Cluster'] + list(analyzer.df.columns[:5])].head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quick Full Analysis\n",
        "\n",
        "Alternatively, run the complete analysis pipeline in one go:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run complete analysis pipeline\n",
        "results = analyzer.run_full_analysis(n_clusters=None)  # None = auto-determine\n",
        "\n",
        "# Access results\n",
        "print(\"\\nAnalysis complete!\")\n",
        "print(f\"Clusters identified: {len(set(analyzer.clusters))}\")\n",
        "print(\"\\nCheck generated files for detailed results.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}